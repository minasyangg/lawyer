<?xml version='1.0' encoding='utf-8'?>
<source type="github_repository"><commit>ed7570586afc56c600bed55ff5e8c39d18ed3101</commit><file name="AUTHENTICATION_GUIDE.md"># ## . ## - **admin** - , - **editor** - , - **user** - ## ### 1. - `/admin/login` - email - : `admin@lawyer-site.com` / `admin123` ### 2. ( admin) - `/admin/users` - ** :** - "add user" - : , email, , - - ** :** - "edit" - , email, ( ) - ** :** - "delete" ### 3. - **user** - (user) - **editor** - (editor) - **admin** - (admin) ## - bcrypt - jwt - middleware - ( ) ## 1. ** :** - : test user - email: test@example.com - : test123 - : user 2. ** ** 3. ** ** ## ```prisma model user { id int @id @default(autoincrement()) name string email string @unique password string role userrole @default(user) status userstatus @default(active) emailverified boolean @default(false) // 2fa ( ) twofactorenabled boolean @default(false) twofactorsecret string? backupcodes string[] @default([]) createdat datetime @default(now()) updatedat datetime @updatedat lastloginat datetime? } enum userrole { admin editor user } ``` ## - email - 2fa ( ) - email - -</file><file name="AUTH_SYSTEM_STATUS.md"># ## ### 1. - **prisma ** : - `userrole` enum (admin, editor, user) - `userstatus` enum (pending, approved, rejected, active, suspended) - `loginattemptresult` enum - `user` 2fa - `loginlog` ### 2. - ** **: speakeasy, qrcode, jsonwebtoken, bcryptjs, nodemailer - ** ** ### 3. - ** ** .env.local: - jwt - email () - rate limiting ### 4. - **rbac ** (`src/lib/auth/permissions.ts`): - - - ### 5. - **totp ** (`src/lib/auth/totp.ts`): - qr - google authenticator - (backup codes) - ### 6. - ** seed ** (`prisma/seeds/seed.js`): - - - ## ( ) ```bash # 1. (postgresql docker) # 2. npm run db:migrate # : enhanced_auth_system # 3. npm run db:fresh # 4. npm run dev ``` ## **:** - email: `admin@lawyer-site.com` - : `adminpass123!` - ** !** - **2fa ** ## ### : 1. ** middleware** - 2. ** auth actions** - 3. **jwt ** - cookie 4. **rate limiting** - 5. ** ** - ### ui : 1. **2fa ** - qr 2. ** ** - 3. ** ** - 4. ** ** - email ## ### : - **jwt ** cookies - **rate limiting** - **2fa ** - **** - ** ** bcrypt (rounds: 12) ### : - **admin**: ( , , ) - **editor**: / , , - **user**: ### : - ** ** pending - ** ** active - ** ** ## 1. ** ** - 2. ** ** - 3. **2fa ** - 4. **email ** - , smtp --- ****: 15 2025 ** **: ****:</file><file name="CLAUDE.md">- prisma - + - + . - : . `unknown`, "" . : 1. props . - react `fc&lt;props&gt;` `react.componenttype&lt;props&gt;`. - promise-. 2. prisma `@prisma/client` . - , prisma. 3. api- server actions (, `{ success: boolean; message?: string; data?: user }`). 4. : - zod . - . 5. : - ui- props. - - . 6. , `arraybuffer`, `buffer` . 7. , , , : , . - .</file><file name="DATABASE_PROVIDER_SETUP.md" /><file name="FILE_MANAGER_README.md"># file manager system next.js . ## - [ ](#-) - [](#) - [ ](#-) - [ ](#-) - [api reference](#api-reference) - [](#) - [ ](#-) - [ ](#-) ## file manager system : - ** ** (admin, editor, user) - **server actions** - ** ** - ** ** - ** ** ## provider server actions: ``` components server actions filemanager provider prisma db file system ``` ## ``` src/lib/filemanager/ types.ts # provider.ts # rolebasedfilemanagerprovider factory.ts # server action src/app/actions/filemanager/ files.ts # server actions folders.ts # server actions editor.ts # server actions src/components/ filemanagertest.tsx # ( ) ``` ## ### admin () ```typescript { canupload: true, // candelete: true, // canviewall: true, // canmanagefolders: true, // / maxfilesize: 50 * 1024 * 1024, // 50mb allowedtypes: ['*'] // } ``` ### editor () ```typescript { canupload: true, // candelete: true, // canviewall: false, // canmanagefolders: false, // maxfilesize: 25 * 1024 * 1024, // 25mb allowedtypes: [ // 'image/jpeg', 'image/png', 'image/gif', 'image/webp', 'application/pdf', 'text/plain', 'application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document' ] } ``` ### user () ```typescript { canupload: false, // candelete: false, // canviewall: false, // canmanagefolders: false, // maxfilesize: 0, // allowedtypes: [] // } ``` ## api reference ### server actions (`/app/actions/filemanager/files.ts`) #### `uploadfiles(formdata: formdata)` . **:** - `formdata` - formdata `folderid` **:** ```typescript { success: boolean; files?: filemanagerfile[]; error?: string; } ``` #### `getfileslist(folderid?: number)` . **:** - `folderid` - id () #### `deletefile(fileid: number)` . ### server actions (`/app/actions/filemanager/folders.ts`) #### `getfolderslist(parentid?: number)` . #### `createfolder(name: string, parentid?: number)` ( admin). #### `deletefolder(folderid: number)` ( admin). ### server actions (`/app/actions/filemanager/editor.ts`) #### `getuserfilepermissions()` . #### `geteditorfiles()` ( ). ## ### 1. ```tsx "use client" import { usestate, useeffect } 'react' import { uploadfiles, getfileslist, deletefile } '@/app/actions/filemanager/files' import { getuserfilepermissions } '@/app/actions/filemanager/editor' export default function myfilemanager() { const [files, setfiles] = usestate([]) const [permissions, setpermissions] = usestate(null) useeffect(() =&gt; { loaddata() }, []) const loaddata = async () =&gt; { const [filesresult, permissionsresult] = await promise.all([ getfileslist(), getuserfilepermissions() ]) (filesresult.success) { setfiles(filesresult.files) } (permissionsresult.success) { setpermissions(permissionsresult.permissions) } } const handleupload = async (event) =&gt; { const formdata = new formdata() const files = event.target.files (let = 0; &lt; files.length; { formdata.append('files', files[i]) } const result = await uploadfiles(formdata) (result.success) { loaddata() // } } return ( &lt;div&gt; {permissions?.canupload &amp;&amp; ( &lt;input type="file" multiple onchange={handleupload} /&gt; )} &lt;div&gt; {files.map(file =&gt; ( &lt;div key={file.id}&gt; &lt;span&gt;{file.filename}&lt;/span&gt; {permissions?.candelete &amp;&amp; ( &lt;button onclick={() =&gt; deletefile(file.id)}&gt; &lt;/button&gt; )} &lt;/div&gt; ))} &lt;/div&gt; &lt;/div&gt; ) } ``` ### 2. ```tsx import { getfolderslist, createfolder } '@/app/actions/filemanager/folders' const handlecreatefolder = async (name: string) =&gt; { const result = await createfolder(name) (result.success) { console.log(' :', result.folder) } } const loadfolders = async () =&gt; { const result = await getfolderslist() (result.success) { setfolders(result.folders) } } ``` ### 3. ```tsx import { getuserfilepermissions } '@/app/actions/filemanager/editor' const checkpermissions = async () =&gt; { const result = await getuserfilepermissions() (result.success) { const { permissions } = result (permissions.canupload) { // } (permissions.canmanagefolders) { // } console.log(' :', permissions.maxfilesize) console.log(' :', permissions.allowedtypes) } } ``` ## ### ```tsx const fileuploader = () =&gt; { const [permissions, setpermissions] = usestate(null) const validatefile = (file: file) =&gt; { (!permissions) return false // (file.size &gt; permissions.maxfilesize) { toast.error(` . : ${permissions.maxfilesize / 1024 / 1024}mb`) return false } // (!permissions.allowedtypes.includes('*') &amp;&amp; !permissions.allowedtypes.includes(file.type)) { toast.error(` : ${file.type}`) return false } return true } const handleupload = async (files: filelist) =&gt; { const validfiles = array.from(files).filter(validatefile) (validfiles.length === 0) { toast.error(' ') return } const formdata = new formdata() validfiles.foreach(file =&gt; formdata.append('files', file)) const result = await uploadfiles(formdata) // ... } return ( // jsx ... ) } ``` ### ```tsx const filebrowser = () =&gt; { const [currentfolder, setcurrentfolder] = usestate(null) const [files, setfiles] = usestate([]) const [folders, setfolders] = usestate([]) const navigatetofolder = async (folderid: number | null) =&gt; { const [filesresult, foldersresult] = await promise.all([ getfileslist(folderid), getfolderslist(folderid) ]) (filesresult.success) setfiles(filesresult.files) (foldersresult.success) setfolders(foldersresult.folders) setcurrentfolder(folderid) } return ( &lt;div&gt; {/* */} &lt;div&gt; {folders.map(folder =&gt; ( &lt;div key={folder.id} onclick={() =&gt; navigatetofolder(folder.id)}&gt; {folder.name} &lt;/div&gt; ))} &lt;/div&gt; {/* */} &lt;div&gt; {files.map(file =&gt; ( &lt;div key={file.id}&gt; {file.filename} &lt;/div&gt; ))} &lt;/div&gt; &lt;/div&gt; ) } ``` ## ### uploadedby `uploadedby`, : ```sql -- ( ) update "file" set "uploadedby" = ( select id "user" role = 'admin' limit 1 ) "uploadedby" null; ``` ### ```javascript // scripts/syncfileownership.js const { prismaclient } = require('@prisma/client') const prisma = new prismaclient() async function syncfileownership() { const adminuser = await prisma.user.findfirst({ { role: 'admin' } }) (!adminuser) { console.error(' ') return } const updatedfiles = await prisma.file.updatemany({ { uploadedby: null }, data: { uploadedby: adminuser.id } }) console.log(` : ${updatedfiles.count}`) } syncfileownership() ``` ## ### `src/lib/filemanager/types.ts`: ```typescript export const role_permissions: record&lt;userrole, rolepermissions&gt; = { admin: { // }, editor: { // maxfilesize: 10 * 1024 * 1024, // 10mb allowedtypes: ['image/jpeg', 'image/png'] // }, user: { // } } ``` ### ```typescript const document_types = [ 'application/pdf', 'application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'application/vnd.ms-excel', 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet' ] // allowedtypes ``` ## 1. ** **: id, 2. ** **: 3. ** **: , 4. ** **: ## - **server actions**: http - **lazy loading**: - ****: next.js revalidatepath - **chunked upload**: formdata ## ### ```typescript // provider.ts console.log('filemanager operation:', { userid: this.userid, userrole: this.userrole, operation: 'upload', filecount: files.length }) ``` ### ```typescript const permissions = await getuserfilepermissions() console.log('user permissions:', permissions) ``` --- ## : 1. ** **: , 2. ** **: 3. ** **: 4. ** **: mime 5. ** **: parent-child .</file><file name="MIGRATION_AUTH_GUIDE.md"># ## 1. ** prisma ** 2. ** ** 2fa 3. ** ** .env.local 4. ** seed ** ## ### 1. (docker postgresql) ### 2. : ```bash # npm run db:migrate # , : # enhanced_auth_system ``` ### 3. : ```bash # npm run db:fresh ``` ## **:** - email: `admin@lawyer-site.com` - : `adminpass123!` - ****: ! - **2fa**: ## ### user: - `role`: enum (admin, editor, user) - `status`: enum (pending, approved, rejected, active, suspended) - `twofactorenabled`, `twofactorsecret`: 2fa - `failedloginattempts`, `lockeduntil`: - `passwordresettoken`, `passwordresetexpires`: - `registrationnote`, `rejectionreason`: ### loginlog: - - ip , user agents - (success, failed, blocked, etc.) ## ### : ```bash # npm run db:reset # npm run db:migrate ``` ### : ```bash # npm run db:fresh ``` ### : ```bash npm run db:status ``` ### prisma studio : ```bash npm run db:studio ``` ## 1. ** **: rbac 2. **2fa **: totp google authenticator 3. ** **: 4. ** middleware**: 5. ** **: ## ```bash # npm run dev # prisma client npx prisma generate # npm run db:studio ``` --- ** **: 15 2025 ****: ****: 1.0.0</file><file name="README.md">[next.js](https://nextjs.org) project bootstrapped [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app). ## getting started first, run development server: ```bash npm run dev # yarn dev # pnpm dev # bun dev ``` open [http://localhost:3000](http://localhost:3000) browser see result. start editing page modifying `app/page.tsx`. page auto-updates edit file. project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) automatically optimize load [geist](https://vercel.com/font), new font family vercel. ## learn learn next.js, take look following resources: - [next.js documentation](https://nextjs.org/docs) - learn next.js features api. - [learn next.js](https://nextjs.org/learn) - interactive next.js tutorial. check next.js github repository](https://github.com/vercel/next.js) - feedback contributions welcome! ## deploy vercel easiest way deploy next.js app use [vercel platform](https://vercel.com/new?utm_medium=default-template&amp;filter=next.js&amp;utm_source=create-next-app&amp;utm_campaign=create-next-app-readme) creators next.js. check [next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) details.</file><file name="components.json">{ "$schema": "https://ui.shadcn.com/schema.json", "style": "new-york", "rsc": true, "tsx": true, "tailwind": { "config": "tailwind.config.js", "css": "src/app/globals.sass", "basecolor": "neutral", "cssvariables": true, "prefix": "" }, "aliases": { "components": "@/components", "utils": "@/lib/utils", "ui": "@/components/ui", "lib": "@/lib", "hooks": "@/hooks" }, "iconlibrary": "lucide-react" }</file><file name="eslint.config.mjs">import { dirname } "path"; import { fileurltopath } "url"; import { flatcompat } "@eslint/eslintrc"; const __filename = fileurltopath(import.meta.url); const __dirname = dirname(__filename); const compat = new flatcompat({ basedirectory: __dirname, }); const eslintconfig = [ ...compat.extends("next/core-web-vitals", "next/typescript"), { ignores: [ "node_modules/**", ".next/**", "build/**", "next-env.d.ts", ], }, ]; export default eslintconfig;</file><file name="get-docker.sh">#!/bin/sh set -e # docker engine linux installation script. # # script intended convenient way configure docker's package # repositories install docker engine, script recommended # production environments. running script, make familiar # potential risks limitations, refer installation manual # https://docs.docker.com/engine/install/ alternative installation methods. # # script: # # - requires `root` `sudo` privileges run. # - attempts detect linux distribution version configure # package management system # - allow customize installation parameters. # - installs dependencies recommendations without asking confirmation. # - installs latest stable release default) docker cli, docker engine, # docker buildx, docker compose, containerd, runc. using script # provision machine, may result unexpected major version upgrades # packages. always test upgrades test environment # deploying production systems. # - designed upgrade existing docker installation. using # script update existing installation, dependencies may updated # expected version, resulting outdated versions. # # source code available https://github.com/docker/docker-install/ # # usage # ============================================================================== # # install latest stable versions docker cli, docker engine, # dependencies: # # 1. download script # # $ curl -fssl https://get.docker.com install-docker.sh # # 2. verify script's content # # $ cat install-docker.sh # # 3. run script --dry-run verify steps executes # # $ sh install-docker.sh --dry-run # # 4. run script either root, using sudo perform installation. # # $ sudo sh install-docker.sh # # command-line options # ============================================================================== # # --version &lt;version&gt; # use --version option install specific version, example: # # $ sudo sh install-docker.sh --version 23.0 # # --channel &lt;stable|test&gt; # # use --channel option install alternative installation channel. # following example installs latest versions "test" channel, # includes pre-releases (alpha, beta, rc): # # $ sudo sh install-docker.sh --channel test # # alternatively, use script https://test.docker.com, uses test # channel default. # # --mirror &lt;aliyun|azurechinacloud&gt; # # use --mirror option install mirror supported script. # available mirrors "aliyun" (https://mirrors.aliyun.com/docker-ce), # "azurechinacloud" (https://mirror.azure.cn/docker-ce), example: # # $ sudo sh install-docker.sh --mirror azurechinacloud # # ============================================================================== # git commit https://github.com/docker/docker-install # script uploaded modified upload job): script_commit_sha="5c8855edd778525564500337f5ac4ad65a0c168e" # strip "v" prefix present version="${version#v}" # channel install # * stable # * test default_channel_value="stable" [ -z "$channel" ]; channel=$default_channel_value fi default_download_url="https://download.docker.com" [ -z "$download_url" ]; download_url=$default_download_url fi default_repo_file="docker-ce.repo" [ -z "$repo_file" ]; repo_file="$default_repo_file" # automatically default staging repo fora # staging download url (download-stage.docker.com) case "$download_url" *-stage*) repo_file="docker-ce-staging.repo";; esac fi mirror='' dry_run=${dry_run:-} [ $# -gt 0 ]; case "$1" --channel) channel="$2" shift ;; --dry-run) dry_run=1 ;; --mirror) mirror="$2" shift ;; --version) version="${2#v}" shift ;; --*) echo "illegal option $1" ;; esac shift $(( $# &gt; 0 ? 1 : 0 )) done case "$mirror" aliyun) download_url="https://mirrors.aliyun.com/docker-ce" ;; azurechinacloud) download_url="https://mirror.azure.cn/docker-ce" ;; "") ;; *) &gt;&amp;2 echo "unknown mirror '$mirror': use either 'aliyun', 'azurechinacloud'." exit 1 ;; esac case "$channel" stable|test) ;; *) &gt;&amp;2 echo "unknown channel '$channel': use either stable test." exit 1 ;; esac command_exists() { command -v "$@" &gt; /dev/null 2&gt;&amp;1 } # version_gte checks version specified $version least given # semver (maj.minor[.patch]), calver (yy.mm) version.it returns 0 (success) # $version either unset (=latest) newer equal specified # version, returns 1 (fail) otherwise. # # examples: # # version=23.0 # version_gte 23.0 // 0 (success) # version_gte 20.10 // 0 (success) # version_gte 19.03 // 0 (success) # version_gte 26.1 // 1 (fail) version_gte() { [ -z "$version" ]; return 0 fi version_compare "$version" "$1" } # version_compare compares two version strings (either semver (major.minor.path), # calver (yy.mm) version strings. returns 0 (success) version newer # equal version b, 1 (fail) otherwise. patch releases pre-release # (-alpha/-beta) taken account # # examples: # # version_compare 23.0.0 20.10 // 0 (success) # version_compare 23.0 20.10 // 0 (success) # version_compare 20.10 19.03 // 0 (success) # version_compare 20.10 20.10 // 0 (success) # version_compare 19.03 20.10 // 1 (fail) version_compare() ( set +x yy_a="$(echo "$1" | cut -f1)" yy_b="$(echo "$2" | cut -f1)" [ "$yy_a" -lt "$yy_b" ]; return 1 fi [ "$yy_a" -gt "$yy_b" ]; return 0 fi mm_a="$(echo "$1" | cut -f2)" mm_b="$(echo "$2" | cut -f2)" # trim leading zeros accommodate calver mm_a="${mm_a#0}" mm_b="${mm_b#0}" [ "${mm_a:-0}" -lt "${mm_b:-0}" ]; return 1 fi return 0 ) is_dry_run() { [ -z "$dry_run" ]; return 1 else return 0 fi } is_wsl() { case "$(uname -r)" *microsoft* ) true ;; # wsl 2 *microsoft* ) true ;; # wsl 1 * ) false;; esac } is_darwin() { case "$(uname *darwin* ) true ;; *darwin* ) true ;; * ) false;; esac } deprecation_notice() { distro=$1 distro_version=$2 echo printf "\033[91;1mdeprecation warning\033[0m\n" printf " linux distribution (\033[1m%s %s\033[0m) reached end-of-life longer supported script.\n" "$distro" "$distro_version" echo " updates security fixes released distribution, users recommended" echo " upgrade currently maintained version $distro." echo printf "press \033[1mctrl+c\033[0m abort script, wait installation continue." echo sleep 10 } get_distribution() { lsb_dist="" # every system officially support /etc/os-release [ -r /etc/os-release ]; lsb_dist="$(. /etc/os-release &amp;&amp; echo "$id")" fi # returning empty string alright since # case statements act unless provide actual value echo "$lsb_dist" } echo_docker_as_nonroot() { is_dry_run; return fi command_exists docker &amp;&amp; [ -e /var/run/docker.sock ]; ( set -x $sh_c 'docker version' ) || true fi # intentionally mixed spaces tabs -- tabs stripped "&lt;&lt;-eof", spaces kept output echo echo "================================================================================" echo version_gte "20.10"; echo run docker non-privileged user, consider setting echo "docker daemon rootless mode user:" echo echo " dockerd-rootless-setuptool.sh install" echo echo "visit https://docs.docker.com/go/rootless/ learn rootless mode." echo fi echo echo run docker daemon fully privileged service, granting non-root" echo "users access, refer https://docs.docker.com/go/daemon-access/" echo echo "warning: access remote api privileged docker daemon equivalent" echo " root access host. refer 'docker daemon attack surface'" echo " documentation details: https://docs.docker.com/go/attack-surface/" echo echo "================================================================================" echo } # check forked linux distro check_forked() { # check lsb_release command existence, usually exists forked distros command_exists lsb_release; # check `-u` option supported set +e lsb_release -u &gt; /dev/null 2&gt;&amp;1 lsb_release_exit_code=$? set -e # check command exited successfully, means forked distro [ "$lsb_release_exit_code" = "0" ]; # print info current distro cat &lt;&lt;-eof using '$lsb_dist' version '$dist_version'. eof # get upstream release info lsb_dist=$(lsb_release -u 2&gt;&amp;1 | tr '[:upper:]' '[:lower:]' | grep -e 'id' | cut ':' -f 2 | tr '[:space:]') dist_version=$(lsb_release -u 2&gt;&amp;1 | tr '[:upper:]' '[:lower:]' | grep -e 'codename' | cut ':' -f 2 | tr '[:space:]') # print info upstream distro cat &lt;&lt;-eof upstream release '$lsb_dist' version '$dist_version'. eof else [ -r /etc/debian_version ] &amp;&amp; [ "$lsb_dist" != "ubuntu" ] &amp;&amp; [ "$lsb_dist" != "raspbian" ]; [ "$lsb_dist" = "osmc" ]; # osmc runs raspbian lsb_dist=raspbian else # debian even know lsb_dist=debian fi dist_version="$(sed /etc/debian_version | sed case "$dist_version" 13) dist_version="trixie" ;; 12) dist_version="bookworm" ;; 11) dist_version="bullseye" ;; 10) dist_version="buster" ;; 9) dist_version="stretch" ;; 8) dist_version="jessie" ;; esac fi fi fi } do_install() { echo "# executing docker install script, commit: $script_commit_sha" command_exists docker; cat &gt;&amp;2 &lt;&lt;-'eof' warning: "docker" command appears already exist system. already docker installed, script cause trouble, displaying warning provide opportunity cancel installation. installed current docker package using script using update docker, ignore message, aware script resets custom changes deb rpm repo configuration files match parameters passed script. may press ctrl+c abort script. eof ( set -x; sleep 20 ) fi user="$(id -un 2&gt;/dev/null || true)" sh_c='sh -c' [ "$user" != 'root' ]; command_exists sudo; sh_c='sudo -e sh -c' elif command_exists su; sh_c='su -c' else cat &gt;&amp;2 &lt;&lt;-'eof' error: installer needs ability run commands root. unable find either "sudo" "su" available make happen. eof exit 1 fi fi is_dry_run; sh_c="echo" fi # perform rudimentary platform detection lsb_dist=$( get_distribution ) lsb_dist="$(echo "$lsb_dist" | tr '[:upper:]' '[:lower:]')" is_wsl; echo echo "wsl detected: recommend using docker desktop windows." echo "please get docker desktop https://www.docker.com/products/docker-desktop/" echo cat &gt;&amp;2 &lt;&lt;-'eof' may press ctrl+c abort script. eof ( set -x; sleep 20 ) fi case "$lsb_dist" ubuntu) command_exists lsb_release; dist_version="$(lsb_release --codename | cut -f2)" fi [ -z "$dist_version" ] &amp;&amp; [ -r /etc/lsb-release ]; dist_version="$(. /etc/lsb-release &amp;&amp; echo "$distrib_codename")" fi ;; debian|raspbian) dist_version="$(sed /etc/debian_version | sed case "$dist_version" 13) dist_version="trixie" ;; 12) dist_version="bookworm" ;; 11) dist_version="bullseye" ;; 10) dist_version="buster" ;; 9) dist_version="stretch" ;; 8) dist_version="jessie" ;; esac ;; centos|rhel) [ -z "$dist_version" ] &amp;&amp; [ -r /etc/os-release ]; dist_version="$(. /etc/os-release &amp;&amp; echo "$version_id")" fi ;; *) command_exists lsb_release; dist_version="$(lsb_release --release | cut -f2)" fi [ -z "$dist_version" ] &amp;&amp; [ -r /etc/os-release ]; dist_version="$(. /etc/os-release &amp;&amp; echo "$version_id")" fi ;; esac # check forked linux distro check_forked # print deprecation warnings distro versions recently reached eol, # may still commonly used (especially lts versions). case "$lsb_dist.$dist_version" centos.8|centos.7|rhel.7) deprecation_notice "$lsb_dist" "$dist_version" ;; debian.buster|debian.stretch|debian.jessie) deprecation_notice "$lsb_dist" "$dist_version" ;; raspbian.buster|raspbian.stretch|raspbian.jessie) deprecation_notice "$lsb_dist" "$dist_version" ;; ubuntu.focal|ubuntu.bionic|ubuntu.xenial|ubuntu.trusty) deprecation_notice "$lsb_dist" "$dist_version" ;; ubuntu.mantic|ubuntu.lunar|ubuntu.kinetic|ubuntu.impish|ubuntu.hirsute|ubuntu.groovy|ubuntu.eoan|ubuntu.disco|ubuntu.cosmic) deprecation_notice "$lsb_dist" "$dist_version" ;; fedora.*) [ "$dist_version" -lt 41 ]; deprecation_notice "$lsb_dist" "$dist_version" fi ;; esac # run setup distro accordingly case "$lsb_dist" ubuntu|debian|raspbian) pre_reqs="ca-certificates curl" apt_repo="deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] $download_url/linux/$lsb_dist $dist_version $channel" ( ! is_dry_run; set -x fi $sh_c 'apt-get -qq update &gt;/dev/null' $sh_c "debian_frontend=noninteractive apt-get -qq install $pre_reqs &gt;/dev/null" $sh_c 'install 0755 /etc/apt/keyrings' $sh_c "curl -fssl \"$download_url/linux/$lsb_dist/gpg\" /etc/apt/keyrings/docker.asc" $sh_c "chmod a+r /etc/apt/keyrings/docker.asc" $sh_c "echo \"$apt_repo\" &gt; /etc/apt/sources.list.d/docker.list" $sh_c 'apt-get -qq update &gt;/dev/null' ) pkg_version="" [ -n "$version" ]; is_dry_run; echo "# warning: version pinning supported dry_run" else # work incomplete versions ie (17.12), may actually grab "latest" test channel pkg_pattern="$(echo "$version" | sed 's/-ce-/~ce~.*/g' | sed 's/-/.*/g')" search_command="apt-cache madison docker-ce | grep '$pkg_pattern' | head -1 | awk '{\$1=\$1};1' | cut ' -f 3" pkg_version="$($sh_c "$search_command")" echo "info: searching repository version '$version'" echo "info: $search_command" [ -z "$pkg_version" ]; echo echo "error: '$version' found amongst apt-cache madison results" echo exit 1 fi version_gte "18.09"; search_command="apt-cache madison docker-ce-cli | grep '$pkg_pattern' | head -1 | awk '{\$1=\$1};1' | cut ' -f 3" echo "info: $search_command" cli_pkg_version="=$($sh_c "$search_command")" fi pkg_version="=$pkg_version" fi fi ( pkgs="docker-ce${pkg_version%=}" version_gte "18.09"; # older versions ship cli containerd separate packages pkgs="$pkgs docker-ce-cli${cli_pkg_version%=} containerd.io" fi version_gte "20.10"; pkgs="$pkgs docker-compose-plugin docker-ce-rootless-extras$pkg_version" fi version_gte "23.0"; pkgs="$pkgs docker-buildx-plugin" fi version_gte "28.2"; pkgs="$pkgs docker-model-plugin" fi ! is_dry_run; set -x fi $sh_c "debian_frontend=noninteractive apt-get -qq install $pkgs &gt;/dev/null" ) echo_docker_as_nonroot exit 0 ;; centos|fedora|rhel) [ "$(uname = "s390x" ]; echo "effective v27.5, please consult rhel distro statement s390x support." exit 1 fi repo_file_url="$download_url/linux/$lsb_dist/$repo_file" ( ! is_dry_run; set -x fi command_exists dnf5; $sh_c "dnf -q --setopt=install_weak_deps=false install dnf-plugins-core" $sh_c "dnf5 config-manager addrepo --overwrite --save-filename=docker-ce.repo --from-repofile='$repo_file_url'" [ "$channel" != "stable" ]; $sh_c "dnf5 config-manager setopt \"docker-ce-*.enabled=0\"" $sh_c "dnf5 config-manager setopt \"docker-ce-$channel.enabled=1\"" fi $sh_c "dnf makecache" elif command_exists dnf; $sh_c "dnf -q --setopt=install_weak_deps=false install dnf-plugins-core" $sh_c "rm -f /etc/yum.repos.d/docker-ce.repo /etc/yum.repos.d/docker-ce-staging.repo" $sh_c "dnf config-manager --add-repo $repo_file_url" [ "$channel" != "stable" ]; $sh_c "dnf config-manager --set-disabled \"docker-ce-*\"" $sh_c "dnf config-manager --set-enabled \"docker-ce-$channel\"" fi $sh_c "dnf makecache" else $sh_c "yum -q install yum-utils" $sh_c "rm -f /etc/yum.repos.d/docker-ce.repo /etc/yum.repos.d/docker-ce-staging.repo" $sh_c "yum-config-manager --add-repo $repo_file_url" [ "$channel" != "stable" ]; $sh_c "yum-config-manager --disable \"docker-ce-*\"" $sh_c "yum-config-manager --enable \"docker-ce-$channel\"" fi $sh_c "yum makecache" fi ) pkg_version="" command_exists dnf; pkg_manager="dnf" pkg_manager_flags="-y -q --best" else pkg_manager="yum" pkg_manager_flags="-y -q" fi [ -n "$version" ]; is_dry_run; echo "# warning: version pinning supported dry_run" else [ "$lsb_dist" = "fedora" ]; pkg_suffix="fc$dist_version" else pkg_suffix="el" fi pkg_pattern="$(echo "$version" | sed 's/-ce-/\\\\.ce.*/g' | sed 's/-/.*/g').*$pkg_suffix" search_command="$pkg_manager list --showduplicates docker-ce | grep '$pkg_pattern' | tail -1 | awk '{print \$2}'" pkg_version="$($sh_c "$search_command")" echo "info: searching repository version '$version'" echo "info: $search_command" [ -z "$pkg_version" ]; echo echo "error: '$version' found amongst $pkg_manager list results" echo exit 1 fi version_gte "18.09"; # older versions support cli package search_command="$pkg_manager list --showduplicates docker-ce-cli | grep '$pkg_pattern' | tail -1 | awk '{print \$2}'" cli_pkg_version="$($sh_c "$search_command" | cut -f 2)" fi # cut epoch prefix '-' pkg_version="-$(echo "$pkg_version" | cut -f 2)" fi fi ( pkgs="docker-ce$pkg_version" version_gte "18.09"; # older versions ship cli containerd separate packages [ -n "$cli_pkg_version" ]; pkgs="$pkgs docker-ce-cli-$cli_pkg_version containerd.io" else pkgs="$pkgs docker-ce-cli containerd.io" fi fi version_gte "20.10"; pkgs="$pkgs docker-compose-plugin docker-ce-rootless-extras$pkg_version" fi version_gte "23.0"; pkgs="$pkgs docker-buildx-plugin docker-model-plugin" fi ! is_dry_run; set -x fi $sh_c "$pkg_manager $pkg_manager_flags install $pkgs" ) echo_docker_as_nonroot exit 0 ;; sles) echo "effective v27.5, please consult sles distro statement s390x support." exit 1 ;; *) [ -z "$lsb_dist" ]; is_darwin; echo echo "error: unsupported operating system 'macos'" echo "please get docker desktop https://www.docker.com/products/docker-desktop" echo exit 1 fi fi echo echo "error: unsupported distribution '$lsb_dist'" echo exit 1 ;; esac exit 1 } # wrapped function protection getting # half file "curl | sh" do_install</file><file name="next.config.ts">import type { nextconfig } "next"; const nextconfig: nextconfig = { // experimental: { serveractions: { bodysizelimit: '10mb', // max_file_size file-utils.ts }, }, // webpack: (config, { isserver }) =&gt; { // config.optimization = { ...config.optimization, splitchunks: { ...config.optimization.splitchunks, cachegroups: { ...config.optimization.splitchunks?.cachegroups, default: { minchunks: 2, priority: -20, reuseexistingchunk: true, }, vendor: { test: /[\\/]node_modules[\\/]/, name: 'vendors', priority: -10, chunks: }, }, }, }; return config; }, // images: { remotepatterns: [ { protocol: 'https', hostname: '*.supabase.co', port: '', pathname: '/storage/v1/object/**', }, ], }, }; export default nextconfig;</file><file name="package.json">{ "name": "lawyer", "version": "0.1.0", "private": true, "scripts": { "dev": "next dev --turbopack", "build": "node --max-old-space-size=4096 node_modules/next/dist/bin/next build", "build:prod": "node scripts/prisma-runner.js generate --prod &amp;&amp; node --max-old-space-size=4096 node_modules/next/dist/bin/next build", "start": "next start", "lint": "eslint", "sync-file-paths": "node scripts/sync-file-paths.js", "postinstall": "prisma generate", "db:migrate": "prisma migrate dev", "db:deploy": "prisma migrate deploy", "db:reset": "prisma migrate reset", "db:seed": "node prisma/seeds/runallseeds.js", "db:studio": "prisma studio", "db:status": "prisma migrate status", "db:fresh": "prisma migrate reset --force &amp;&amp; node prisma/seeds/runallseeds.js", "db:migrate:prod": "node scripts/prisma-runner.js migrate deploy --prod", "db:deploy:prod": "node scripts/prisma-runner.js migrate deploy --prod", "db:seed:prod": "node scripts/prisma-runner.js db seed --prod &amp;&amp; node prisma/seeds/runallseeds.js", "db:studio:prod": "node scripts/prisma-runner.js studio --prod", "db:status:prod": "node scripts/prisma-runner.js migrate status --prod", "db:fresh:prod": "node scripts/prisma-runner.js migrate reset --force --prod &amp;&amp; node prisma/seeds/runallseeds.js", "db:seed:single": "node prisma/seeds/seed.js" }, "dependencies": { "@aws-sdk/client-s3": "^3.884.0", "@hookform/resolvers": "^5.2.1", "@prisma/client": "^6.14.0", "@supabase/supabase-js": "^2.57.2", "@tinymce/tinymce-react": "^6.3.0", "@types/bcryptjs": "^3.0.0", "bcryptjs": "^3.0.2", "clsx": "^2.1.1", "jsonwebtoken": "^9.0.2", "lucide-react": "^0.542.0", "mime-types": "^3.0.1", "multer": "^2.0.2", "next": "15.5.0", "next-auth": "^4.24.11", "nodemailer": "^6.10.1", "prisma": "^6.14.0", "qrcode": "^1.5.4", "react": "19.1.0", "react-dom": "19.1.0", "react-hook-form": "^7.62.0", "react-hot-toast": "^2.6.0", "sharp": "^0.34.3", "sonner": "^2.0.7", "speakeasy": "^2.0.0", "tailwind-merge": "^3.3.1", "ts-node": "^10.9.2", "zod": "^4.1.5" }, "devdependencies": { "@eslint/eslintrc": "^3", "@tailwindcss/postcss": "^4", "@types/mime-types": "^3.0.1", "@types/multer": "^2.0.0", "@types/node": "^20", "@types/react": "^19", "@types/react-dom": "^19", "cross-env": "^10.0.0", "dotenv-cli": "^10.0.0", "eslint": "^9", "eslint-config-next": "15.5.0", "sass": "^1.91.0", "tailwindcss": "^4", "typescript": "^5" } }</file><file name="postcss.config.mjs">const config = { plugins: ["@tailwindcss/postcss"], }; export default config;</file><file name="problems.md">### 1. slug . . toaster. 2. . , . 3. : 1. html . . 2. . 1. . 2. . . , . 3. . 4. . 5. .</file><file name="tsconfig.json">{ "compileroptions": { "target": "es2017", "lib": ["dom", "dom.iterable", "esnext"], "allowjs": true, "skiplibcheck": true, "strict": true, "noemit": true, "esmoduleinterop": true, "module": "esnext", "moduleresolution": "bundler", "resolvejsonmodule": true, "isolatedmodules": true, "jsx": "preserve", "incremental": true, "plugins": [ { "name": "next" } ], "paths": { "@/*": ["./src/*"] } }, "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"], "exclude": ["node_modules", "prisma"] }</file><file name=".claude/.claude-instructions.md"># - ## - ** **: - - ****: next.js 15.5.0 app router - ****: typescript - ** **: sqlite prisma orm - ****: sass + tailwind css ## ```json { "frontend": "next.js 15.5.0 + react 19", "styling": "sass + tailwind css", "database": "sqlite + prisma", "typescript": "typescript 5", "bundler": "turbopack" } ``` ## ``` src/ app/ # app router layout.tsx # layout page.tsx # globals.sass # components/ forms/ # contactform.tsx section/ # sectionactuality.tsx sectioninfo.tsx sectionservices.tsx ui/ # ui header.tsx footer.tsx mainbanner.tsx servicedescription.tsx servicedetails.tsx buttons/ prisma/ schema.prisma # dev.db # sqlite ``` ## ### service () ```prisma model service { id int @id @default(autoincrement()) title string # description string # extrainfo string? # } ``` ## ### (/) : 1. **header** - 2. **mainbanner** - 3. **sectioninfo** - 4. **sectionservices** - 5. **buttonfeedback** - ( ) 6. **sectionactuality** - 7. **footer** - ### - `/services` - - `/publications` - / - `/contacts` - - - ## ```bash npm run dev # (turbopack) npm run build # npm run start # npm run lint # eslint ``` ## - server components - api routes `src/app/api/` - prisma - - `/public/img/` ## - next.js - prisma + sqlite - ui - sass + tailwind - : api - : , ## - - - - next.js app router</file><file name=".claude/settings.local.json">{ "permissions": { "allow": [ "bash(claude config list)", "bash(claude mcp add:*)", "bash(claude mcp:*)", "bash(mcp list:*)", "bash(npm run build:*)" ], "deny": [], "ask": [] } }</file><file name=".readme/DATABASE_PROVIDER_SETUP.md"># database provider system (simplified) . ## supabase . ## ### local () - ****: `.env.local` - ** **: postgresql docker - ****: prisma ### production (supabase) - ****: `.env.production` - ** **: supabase postgresql - ****: direct_url ( pgbouncer) ## ### ```bash npm run db:migrate # prisma migrate dev npm run db:seed # seed npm run db:studio # prisma studio npm run db:reset # npm run db:fresh # reset + seed ``` ### (supabase) ```bash npm run db:migrate:prod # migrate deploy direct_url npm run db:deploy:prod # migrate:prod npm run db:seed:prod # seed supabase npm run db:studio:prod # studio supabase npm run db:fresh:prod # reset + seed supabase ``` ## ### runner `scripts/prisma-runner.js` : 1. ** .env ** (.env.local .env.production) 2. ** supabase ** database_url direct_url 3. ** prisma ** ### supabase ```javascript // direct_url (isprod &amp;&amp; command === 'migrate') { process.env.database_url = envvars.direct_url; // pgbouncer! } ``` ## ### .env.local ```bash database_url="postgresql://postgres:1234@localhost:5432/mydb?schema=public" direct_url="postgresql://postgres:1234@localhost:5432/mydb?schema=public" ``` ### .env.production ```bash # connection pooling database_url="postgresql://postgres.xxx:[password]@aws-xxx.pooler.supabase.com:6543/postgres?pgbouncer=true" # ( pgbouncer!) direct_url="postgresql://postgres.xxx:[password]@aws-xxx.pooler.supabase.com:5432/postgres" ``` ## 1. ** ** .mjs 2. ** ** - 3. ** supabase** - direct_url 4. ** ** - npm run 5. ** ** - ## , supabase . **:** ```bash npm run db:migrate:prod ``` supabase direct_url.</file><file name=".readme/DOCUMENTMANAGER_FIX.md" /><file name=".readme/SUPABASE_SETUP.md"># supabase ## 1. [supabase](https://supabase.com) 2. ( ) 3. ## ### supabase dashboard: 1. **project settings api**: - `project url` `supabase_url` - `anon public` `supabase_anon_key` - `service_role` `supabase_service_role_key` 2. **project settings database**: - "connection string" - : `postgresql://postgres:[your-password]@db.[project-ref].supabase.co:5432/postgres` - `database_url` `direct_url` ## 1. `.env` supabase 2. : ```bash # prisma npm run postinstall # supabase npm run db:push # : npm run db:studio ``` ## vercel 1. vercel 2. "environment variables" 3. `.env.production`: - `supabase_url` - `supabase_anon_key` - `supabase_service_role_key` - `database_url` - `direct_url` - 4. redeploy ## ( ) sqlite : 1. sqlite3: `npm install sqlite3` 2. : `node scripts/migrate-to-supabase.js` ## 1. supabase dashboard table editor 2. , 3. vercel ## ```bash # npx prisma migrate status # ( !) npm run db:reset # npm run db:push # npm run db:migrate # npm run db:deploy ```</file><file name=".readme/promts/figma-promts.md">## figma figma next.js + tailwindcss: 1. : &lt;div classname="container mx-auto max-w-screen-xl px-4"&gt; ... &lt;/div&gt; bootstrap "container". 2. , , 100% (, full-width background). 3. tailwindcss : - flex, grid, gap, space-y - sm:, md:, lg:, xl: - text-center, sm:text-left 4. next.js &lt;image&gt;: import image "next/image" &lt;image src="/path.jpg" alt="" width={600} height={400} classname="rounded-lg" priority /&gt; web- lazy-loading. 5. , alt="" . 6. : &lt;h1&gt;, &lt;h2&gt;, &lt;p&gt;, &lt;ul&gt;, &lt;li&gt;, &lt;section&gt;, &lt;article&gt; .. 7. , mobile-friendly : - : w-full - grid flex col-span / basis 8. css , utility- tailwind. 9. (, , ) react- /components/ui/{component-name} 10. figma 11.</file><file name=".readme/promts/project-structure.md"># ## : - `src/app` - app router - `/components` - ui - `/lib` - - `/public` - ## : - next.js 15 - typescript - tailwind css - prisma ( ) ## - server components - api routes src/app/api/ - middleware - prisma sqllite - adminjs ## - pages - home - services - publications - contacts - describe ### homepage : section homeinfo section services button feedback : feedback section actuality section articles : . otherarticlebutton /publications button subscribe section footer ### publicationpage :</file><file name=".readme/promts/supabaseStorage.md">: supabase storage : next.js : uploads s3 sweb . : supabase storage . . dev prod. : admin editor : (vercel ) npm run build typescript - : 1: (15 ) 1.1. src/lib/storage/interfaces/storage-provider.ts storageprovider : uploadfile, deletefile, getfileurl, listfiles, createfolder, deletefolder : storagefile, uploadoptions, storageresult uploadoptions : userid, userrole ('admin'|'editor'), category ('articles'|'documents'), folder?, replace? 1.2. src/lib/storage/config/storage-config.ts storageconfig storage_config : getenvironmentprefix() - 'prod' 'dev' node_env getuserpath() - {env}/{role}/user_{id} getfilepath() - 1.3. npm run build 2: localstorageprovider (30 ) 2.1. src/lib/storage/providers/local-storage-provider.ts localstorageprovider storageprovider file-utils.ts api 2.2. uploadfile: storage_config.getfilepath() uploads storageresult 2.3. 2.4. npm run build 3: supabasestorageprovider (45 ) 3.1. src/lib/storage/providers/supabase-storage-provider.ts supabasestorageprovider storageprovider @supabase/storage-js supabase env 3.2. uploadfile: storage_config.getfilepath() bucket bucket supabase_storage_bucket file, buffer url 3.3. deletefile: supabase storage 3.4. getfileurl: url supabase storage , 3.5. createfolder, deletefolder: ( ) 3.6. supabase 3.7. npm run build 4: (15 ) 4.1. src/lib/storage/factory/storage-factory.ts createstorageprovider() : supabase_url, supabase_service_role_key, supabase_storage_bucket - supabase, - 4.2. src/lib/storage/index.ts storage 4.3. npm run build 5: (5 ) 5.1. .env.production: 5.2. .env.local ( ) 6: api endpoints (30 ) 6.1. route.ts: file-utils storage storage @/lib/storage userid userrole uploadoptions 6.2. route.ts: , storage category: 'articles' 6.3. route.ts: storage 6.4. npm run build 7: server actions (45 ) 7.1. uploadfile.ts: savefileuniversal storage.uploadfile uploadoptions 7.2. deletefile.ts: storage.deletefile 7.3. deletefolder.ts: storage.deletefolder 7.4. createfolder.ts: storage.createfolder mkdir 7.5. actions 7.6. action npm run build 8: (30 ) 8.1. : npm run build 8.2. typescript 8.3. 8.4. : localstorageprovider supabase supabasestorageprovider : .</file><file name=".readme/promts/pages/uslugiPagePromt.md"># next.js 15 ## next.js 15 app router : ### 1. url - url: `/services` - url: `/services/[slug]` slug - - : `/services/web-dev`, `/services/mobile-dev`, `/services/ui-design` ### 2. ** ( ):** 1. **header** - /components/ui/header 2. **servicedescription** - 4. **servicedetails** - . figma. **servicedescription** . 5. **buttonfeedback** - /components/ui/buttons 5. **footer** - /components/ui/header ### 3. - servicesnavigation: - url `/services/[slug]` - - servicedescription servicedetails - (client-side navigation) ### 4. : ```typescript interface service { id: string title: string slug: string shortdescription: string fulldescription: string features: string[] benefits: string[] price: string duration: string technologies?: string[] portfolio?: portfolioitem[] } ``` ** :** 1. **-** (slug: 'web-dev') 2. ** ** (slug: 'mobile-dev') 3. **ui/ux ** (slug: 'ui-design') 4. **seo ** (slug: 'seo') 5. **** (slug: 'support') ### 5. servicedescription : - - - () - " " " " - ### 6. servicedetails : - - - ( ) - - faq - - ### 7. ux - tailwind css - responsive ( , , ) - - loading - ux ### 8. seo - title description - open graph - structured data ### 9. - typescript - error boundaries - 404 - breadcrumbs - ### 10. ``` app/ services/ page.tsx # redirect [slug]/ page.tsx # layout.tsx # layout header/footer components/ header.tsx footer.tsx servicesnavigation.tsx servicedescription.tsx servicedetails.tsx ui/ # ui lib/ services.ts # api ``` ## : - - - - seo-friendly urls - responsive - typescript - ui/ux .</file><file name=".vscode/settings.json">{ "willluke.nextjs.addtypesonsave": true, "willluke.nextjs.hasprompted": true }</file><file name="prisma/prisma-note.md">: 1. : # rm prisma/dev.db # npx prisma db push # npx prisma generate 2. (seeds): # seed npx tsx prisma/seeds/seedservices.ts npx tsx prisma/seeds/seedservicedetails.ts 3. ( ): # npx prisma db push # ( production) npx prisma migrate dev --name migration_name # npx prisma studio 4. : # npx prisma generate # npx prisma migrate status</file><file name="prisma/schema.prisma">model fileentity { id int @id @default(autoincrement()) userid int name string isfolder boolean parentid int? path string? size int? mimetype string? url string? createdat datetime @default(now()) parent fileentity? @relation("folderparent", fields: [parentid], references: [id]) children fileentity[] @relation("folderparent") user user @relation(fields: [userid], references: [id]) } // prisma schema file, // learn docs: https://pris.ly/d/prisma-schema generator client { provider = "prisma-client-js" } datasource db { provider = "postgresql" url = env("database_url") directurl = env("direct_url") } // enums enum userrole { admin editor user } enum userstatus { pending // ( ) approved // rejected // active // suspended // } enum loginattemptresult { success failed blocked two_factor_required two_factor_failed } model service { id int @id @default(autoincrement()) title string @unique description string extrainfo string? details servicedetails[] articles article[] } model servicedetails { id int @id @default(autoincrement()) category string services string serviceid int? service service? @relation(fields: [serviceid], references: [id]) } model user { id int @id @default(autoincrement()) name string email string @unique password string? role userrole @default(user) status userstatus @default(active) // 2fa twofactorenabled boolean @default(false) twofactorsecret string? @unique twofactorbackupcodes json? // backup // isactive boolean @default(true) emailverified boolean @default(false) lastlogin datetime? failedloginattempts int @default(0) lockeduntil datetime? // passwordresettoken string? @unique passwordresetexpires datetime? // registrationnote string? // rejectionreason string? // // timestamps createdat datetime @default(now()) updatedat datetime @updatedat // relations articles article[] files file[] folders folder[] fileentities fileentity[] loginlogs loginlog[] // / createdusers user[] @relation("usercreatedby") createdby user? @relation("usercreatedby", fields: [createdbyid], references: [id]) createdbyid int? @@index([email]) @@index([status]) @@index([role]) } // model loginlog { id int @id @default(autoincrement()) userid int? // null email string ipaddress string? useragent string? result loginattemptresult failurereason string? // "invalid_password", "account_locked", "2fa_required", etc. twofactorused boolean @default(false) sessionid string? // id createdat datetime @default(now()) user user? @relation(fields: [userid], references: [id], ondelete: cascade) @@index([userid]) @@index([email]) @@index([ipaddress]) @@index([createdat]) @@index([result]) } model article { id int @id @default(autoincrement()) title string content string excerpt string? slug string @unique published boolean @default(false) categoryid int? authorid int documents json? // json createdat datetime @default(now()) updatedat datetime @updatedat author user @relation(fields: [authorid], references: [id]) category service? @relation(fields: [categoryid], references: [id]) tags articletag[] } model tag { id int @id @default(autoincrement()) name string @unique slug string @unique color string? createdat datetime @default(now()) articles articletag[] } model articletag { articleid int tagid int article article @relation(fields: [articleid], references: [id], ondelete: cascade) tag tag @relation(fields: [tagid], references: [id], ondelete: cascade) @@id([articleid, tagid]) } model file { id int @id @default(autoincrement()) originalname string filename string @unique path string // storage ( ) virtualpath string @default("") // virtualid string? @unique // () mimetype string size int uploadedby int folderid int? createdat datetime @default(now()) uploader user @relation(fields: [uploadedby], references: [id]) folder folder? @relation(fields: [folderid], references: [id]) @@index([uploadedby]) @@index([virtualpath]) @@index([virtualid]) } model folder { id int @id @default(autoincrement()) name string path string virtualpath string? // () virtualid string? @unique // () ownerid int parentid int? createdat datetime @default(now()) owner user @relation(fields: [ownerid], references: [id]) parent folder? @relation("folderhierarchy", fields: [parentid], references: [id]) children folder[] @relation("folderhierarchy") files file[] @@unique([ownerid, path]) @@index([virtualpath]) @@index([virtualid]) }</file><file name="prisma/schema_update.prisma" /><file name="prisma/migrations/migration_lock.toml"># please edit file manually # added version-control system (e.g., git) provider = "postgresql"</file><file name="prisma/migrations/20250908132650_init_postgresql/migration.sql">-- createtable create table "public"."fileentity" ( "id" serial null, "userid" integer null, "name" text null, "isfolder" boolean null, "parentid" integer, "path" text, "size" integer, "mimetype" text, "url" text, "createdat" timestamp(3) null default current_timestamp, constraint "fileentity_pkey" primary key ("id") ); -- createtable create table "public"."service" ( "id" serial null, "title" text null, "description" text null, "extrainfo" text, constraint "service_pkey" primary key ("id") ); -- createtable create table "public"."servicedetails" ( "id" serial null, "category" text null, "services" text null, "serviceid" integer, constraint "servicedetails_pkey" primary key ("id") ); -- createtable create table "public"."user" ( "id" serial null, "name" text null, "email" text null, "password" text, "role" text null default 'user', "createdat" timestamp(3) null default current_timestamp, "updatedat" timestamp(3) null, constraint "user_pkey" primary key ("id") ); -- createtable create table "public"."article" ( "id" serial null, "title" text null, "content" text null, "excerpt" text, "slug" text null, "published" boolean null default false, "categoryid" integer, "authorid" integer null, "documents" jsonb, "createdat" timestamp(3) null default current_timestamp, "updatedat" timestamp(3) null, constraint "article_pkey" primary key ("id") ); -- createtable create table "public"."tag" ( "id" serial null, "name" text null, "slug" text null, "color" text, "createdat" timestamp(3) null default current_timestamp, constraint "tag_pkey" primary key ("id") ); -- createtable create table "public"."articletag" ( "articleid" integer null, "tagid" integer null, constraint "articletag_pkey" primary key ("articleid","tagid") ); -- createtable create table "public"."file" ( "id" serial null, "originalname" text null, "filename" text null, "path" text null, "virtualpath" text null default '', "virtualid" text, "mimetype" text null, "size" integer null, "uploadedby" integer null, "folderid" integer, "createdat" timestamp(3) null default current_timestamp, constraint "file_pkey" primary key ("id") ); -- createtable create table "public"."folder" ( "id" serial null, "name" text null, "path" text null, "virtualpath" text, "virtualid" text, "ownerid" integer null, "parentid" integer, "createdat" timestamp(3) null default current_timestamp, constraint "folder_pkey" primary key ("id") ); -- createindex create unique index "user_email_key" "public"."user"("email"); -- createindex create unique index "article_slug_key" "public"."article"("slug"); -- createindex create unique index "tag_name_key" "public"."tag"("name"); -- createindex create unique index "tag_slug_key" "public"."tag"("slug"); -- createindex create unique index "file_filename_key" "public"."file"("filename"); -- createindex create unique index "file_virtualid_key" "public"."file"("virtualid"); -- createindex create index "file_uploadedby_idx" "public"."file"("uploadedby"); -- createindex create index "file_virtualpath_idx" "public"."file"("virtualpath"); -- createindex create index "file_virtualid_idx" "public"."file"("virtualid"); -- createindex create unique index "folder_virtualid_key" "public"."folder"("virtualid"); -- createindex create index "folder_virtualpath_idx" "public"."folder"("virtualpath"); -- createindex create index "folder_virtualid_idx" "public"."folder"("virtualid"); -- createindex create unique index "folder_ownerid_path_key" "public"."folder"("ownerid", "path"); -- addforeignkey alter table "public"."fileentity" add constraint "fileentity_parentid_fkey" foreign key ("parentid") references "public"."fileentity"("id") delete set null update cascade; -- addforeignkey alter table "public"."fileentity" add constraint "fileentity_userid_fkey" foreign key ("userid") references "public"."user"("id") delete restrict update cascade; -- addforeignkey alter table "public"."servicedetails" add constraint "servicedetails_serviceid_fkey" foreign key ("serviceid") references "public"."service"("id") delete set null update cascade; -- addforeignkey alter table "public"."article" add constraint "article_authorid_fkey" foreign key ("authorid") references "public"."user"("id") delete restrict update cascade; -- addforeignkey alter table "public"."article" add constraint "article_categoryid_fkey" foreign key ("categoryid") references "public"."service"("id") delete set null update cascade; -- addforeignkey alter table "public"."articletag" add constraint "articletag_articleid_fkey" foreign key ("articleid") references "public"."article"("id") delete cascade update cascade; -- addforeignkey alter table "public"."articletag" add constraint "articletag_tagid_fkey" foreign key ("tagid") references "public"."tag"("id") delete cascade update cascade; -- addforeignkey alter table "public"."file" add constraint "file_uploadedby_fkey" foreign key ("uploadedby") references "public"."user"("id") delete restrict update cascade; -- addforeignkey alter table "public"."file" add constraint "file_folderid_fkey" foreign key ("folderid") references "public"."folder"("id") delete set null update cascade; -- addforeignkey alter table "public"."folder" add constraint "folder_ownerid_fkey" foreign key ("ownerid") references "public"."user"("id") delete restrict update cascade; -- addforeignkey alter table "public"."folder" add constraint "folder_parentid_fkey" foreign key ("parentid") references "public"."folder"("id") delete set null update cascade;</file><file name="prisma/migrations/20250915152853_/migration.sql">/* warnings: - `role` column `user` table would dropped recreated. lead data loss data column. - unique constraint covering columns `[twofactorsecret]` table `user` added. existing duplicate values, fail. - unique constraint covering columns `[passwordresettoken]` table `user` added. existing duplicate values, fail. */ -- createenum create type "public"."userrole" enum ('admin', 'editor', 'user'); -- createenum create type "public"."userstatus" enum ('pending', 'approved', 'rejected', 'active', 'suspended'); -- createenum create type "public"."loginattemptresult" enum ('success', 'failed', 'blocked', 'two_factor_required', 'two_factor_failed'); -- altertable alter table "public"."user" add column "createdbyid" integer, add column "emailverified" boolean null default false, add column "failedloginattempts" integer null default 0, add column "isactive" boolean null default true, add column "lastlogin" timestamp(3), add column "lockeduntil" timestamp(3), add column "passwordresetexpires" timestamp(3), add column "passwordresettoken" text, add column "registrationnote" text, add column "rejectionreason" text, add column "status" "public"."userstatus" null default 'active', add column "twofactorbackupcodes" jsonb, add column "twofactorenabled" boolean null default false, add column "twofactorsecret" text, drop column "role", add column "role" "public"."userrole" null default 'user'; -- createtable create table "public"."loginlog" ( "id" serial null, "userid" integer, "email" text null, "ipaddress" text, "useragent" text, "result" "public"."loginattemptresult" null, "failurereason" text, "twofactorused" boolean null default false, "sessionid" text, "createdat" timestamp(3) null default current_timestamp, constraint "loginlog_pkey" primary key ("id") ); -- createindex create index "loginlog_userid_idx" "public"."loginlog"("userid"); -- createindex create index "loginlog_email_idx" "public"."loginlog"("email"); -- createindex create index "loginlog_ipaddress_idx" "public"."loginlog"("ipaddress"); -- createindex create index "loginlog_createdat_idx" "public"."loginlog"("createdat"); -- createindex create index "loginlog_result_idx" "public"."loginlog"("result"); -- createindex create unique index "user_twofactorsecret_key" "public"."user"("twofactorsecret"); -- createindex create unique index "user_passwordresettoken_key" "public"."user"("passwordresettoken"); -- createindex create index "user_email_idx" "public"."user"("email"); -- createindex create index "user_status_idx" "public"."user"("status"); -- createindex create index "user_role_idx" "public"."user"("role"); -- addforeignkey alter table "public"."user" add constraint "user_createdbyid_fkey" foreign key ("createdbyid") references "public"."user"("id") delete set null update cascade; -- addforeignkey alter table "public"."loginlog" add constraint "loginlog_userid_fkey" foreign key ("userid") references "public"."user"("id") delete cascade update cascade;</file><file name="prisma/migrations/20250915204738_/migration.sql">/* warnings: - unique constraint covering columns `[title]` table `service` added. existing duplicate values, fail. */ -- createindex create unique index "service_title_key" "public"."service"("title");</file><file name="prisma/seeds/resetAdminPassword.js">const { prismaclient } = require('@prisma/client') const bcrypt = require('bcryptjs') const prisma = new prismaclient() async function main() { const email = 'admin@lawyer.com' const newpassword = 'admin' const hash = await bcrypt.hash(newpassword, 12) const user = await prisma.user.upsert({ { email }, update: { password: hash, name: 'administrator', role: 'admin' }, create: { name: 'administrator', email, password: hash, role: 'admin' } }) console.log('admin password set user.email) } main() .catch((e) =&gt; { console.error(e) process.exit(1) }) .finally(async () =&gt; { await prisma.$disconnect() })</file><file name="prisma/seeds/runAllSeeds.js">const fs = require('fs'); const path = require('path'); const { spawnsync } = require('child_process'); const seedsdir = __dirname; const files = fs.readdirsync(seedsdir) .filter(f =&gt; /^seed.*\.js$/.test(f) &amp;&amp; f !== 'runallseeds.js'); (files.length === 0) { console.log('no seed files found.'); process.exit(0); } (const file files) { const fullpath = path.join(seedsdir, file); console.log(`\nrunning seed: ${file}`); const result = spawnsync('node', [fullpath], { stdio: 'inherit' }); (result.status !== 0) { console.error(`seed ${file} failed exit code ${result.status}`); process.exit(result.status); } } console.log('\nall seeds completed successfully.');</file><file name="prisma/seeds/seed.js">const { prismaclient } = require('@prisma/client'); const bcrypt = require('bcryptjs'); const prisma = new prismaclient(); async function main() { try { console.log(' seeding ...'); // ( , ) await prisma.user.deletemany({ { role: { { ['admin', 'editor', 'user'] } } } }); // const adminpassword = 'adminpass123!'; // const hashedpassword = await bcrypt.hash(adminpassword, 12); const admin = await prisma.user.upsert({ { email: 'admin@lawyer-site.com' }, update: { name: 'system administrator', password: hashedpassword, role: 'admin', status: 'active', isactive: true, emailverified: true, twofactorenabled: false, // failedloginattempts: 0, createdat: new date(), updatedat: new date() }, create: { name: 'system administrator', email: 'admin@lawyer-site.com', password: hashedpassword, role: 'admin', status: 'active', isactive: true, emailverified: true, twofactorenabled: false, failedloginattempts: 0 } }); console.log(' :'); console.log(` email: admin@lawyer-site.com`); console.log(` : ${adminpassword}`); console.log(` : !`); console.log(` 2fa `); console.log(' seeding !'); } catch (error) { console.error(' seeding:', error); process.exit(1); } finally { await prisma.$disconnect(); } } main();</file><file name="prisma/seeds/seedArticles.ts">import { prismaclient } '@prisma/client'; import bcrypt 'bcryptjs'; const prisma = new prismaclient(); async function main() { // create admin user password exists const adminuser = await prisma.user.upsert({ { email: 'admin@example.com' }, update: {}, create: { name: 'admin user', email: 'admin@example.com', password: await bcrypt.hash('admin123', 10), role: 'admin' } }); // get services categorization const services = await prisma.service.findmany(); (services.length === 0) { console.log('no services found. please run services seed first.'); return; } const articles = [ { title: " 2024", slug: "novye-izmeneniya-v-nalogovom-zakonodatelstve-2024", content: ` 2024 , , . : 1. -. . 2. . . 3. . : - - - .`, excerpt: " 2024 .", published: true, categoryid: services.find(s =&gt; s.title.includes(''))?.id || services[0].id, authorid: adminuser.id }, { title: " : ", slug: "procedura-bankrotstva-fizicheskih-lic-poshagovoe-rukovodstvo", content: ` , . : 1. 500 000 2. 3 3. : 1. - 3 - - - 2. . 3. . 4. . : - ( ) - - 5 : . .`, excerpt: " : , .", published: true, categoryid: services.find(s =&gt; s.title.includes(''))?.id || services[0].id, authorid: adminuser.id }, { title: " ", slug: "zaschita-intellectualnoy-sobstvennosti-v-cifrovuyu-epohu", content: ` . : 1. - - - 2. - - - 3. - - - : 1. 2. 3. - 4. : 1. - - - 2. - drm- - - - 3. - - - : - - - - `, excerpt: " -.", published: true, categoryid: services.find(s =&gt; s.title.includes(''))?.id || services[0].id, authorid: adminuser.id }, { title: " : ", slug: "korporativnye-spory-kak-zaschitit-interesy-biznesa", content: ` . . : 1. - - - 2. - - - 3. - - - : 1. - - - 2. - - - 3. - - - : 1. . 2. . 3. . 4. - - - : - - - - : .`, excerpt: " .", published: true, categoryid: services.find(s =&gt; s.title.includes(''))?.id || services[0].id, authorid: adminuser.id }, { title: " ", slug: "kompleksnoe-yuridicheskoe-soprovozhdenie-startapov", content: ` . . : 1. - - : - - 2. - - - 3. - - due diligence - 4. - - - : 1. mvp - - ip - 2. - due diligence - - 3. - - - 4. (exit) - ipo - m&amp;a - : 1. 2. 3. 4. : - - - - , .`, excerpt: " .", published: false, // draft article categoryid: services.find(s =&gt; s.title.includes(''))?.id || services[0].id, authorid: adminuser.id } ]; (const articledata articles) { await prisma.article.create({ data: articledata }); } console.log('articles seeded successfully'); } main() .catch((e) =&gt; { console.error(e); process.exit(1); }) .finally(async () =&gt; { await prisma.$disconnect(); });</file><file name="prisma/seeds/seedServiceDetails.js">const { prismaclient } = require('@prisma/client'); const prisma = new prismaclient(); async function main() { const servicedetails = [ { category: " ", services: "1. \n2. \n3. \n4. \n5. " }, { category: " ", services: "1. \n2. -\n3. \n4. " }, { category: " ", services: "1. \n2. \n3. \n4. \n5. \n6. \n7. \n8. \n9. \n10. \n11. due diligence " }, { category: " ( )", services: "1. , \n2. it\n3. \n4. \n5. \n6. \n7. " }, { category: " ", services: "1. , \n2. it\n3. \n4. \n5. \n6. \n7. " }, { category: " ", services: "1. , \n2. it\n3. \n4. \n5. \n6. \n7. " }, { category: " ", services: "1. , \n2. it\n3. \n4. \n5. \n6. \n7. " } ]; (const detail servicedetails) { await prisma.servicedetails.create({ data: detail }); } console.log('service details seeded successfully'); } main() .catch((e) =&gt; { console.error(e); process.exit(1); }) .finally(async () =&gt; { await prisma.$disconnect(); });</file><file name="prisma/seeds/seedServiceDetails.ts">import { prismaclient } '@prisma/client'; const prisma = new prismaclient(); async function main() { const servicedetails = [ { category: " ", services: "1. \n2. \n3. \n4. \n5. " }, { category: " ", services: "1. \n2. -\n3. \n4. " }, { category: " ", services: "1. \n2. \n3. \n4. \n5. \n6. \n7. \n8. \n9. \n10. \n11. due diligence " }, { category: " ( )", services: "1. , \n2. it\n3. \n4. \n5. \n6. \n7. " }, { category: " ", services: "1. , \n2. it\n3. \n4. \n5. \n6. \n7. " }, { category: " ", services: "1. , \n2. it\n3. \n4. \n5. \n6. \n7. " }, { category: " ", services: "1. , \n2. it\n3. \n4. \n5. \n6. \n7. " } ]; (const detail servicedetails) { await prisma.servicedetails.create({ data: detail }); } console.log('service details seeded successfully'); } main() .catch((e) =&gt; { console.error(e); process.exit(1); }) .finally(async () =&gt; { await prisma.$disconnect(); });</file><file name="prisma/seeds/seedServices.js">const { prismaclient } = require('@prisma/client'); const prisma = new prismaclient(); async function main() { const services = [ { title: " ", description: " . .", extrainfo: " , . , . , . , , ." }, { title: " ", description: " , , , . : , .", extrainfo: " , ." }, { title: " ", description: "subheading sets context, shares info author, generally gets people psyched keep reading", extrainfo: null }, { title: " ", description: " -. , .", extrainfo: " : , , (, , ), , . , . ." }, { title: " ", description: "subheading sets context, shares info author, generally gets people psyched keep reading", extrainfo: null }, { title: " ", description: "subheading sets context, shares info author, generally gets people psyched keep reading", extrainfo: null } ]; (const service services) { await prisma.service.create({ data: service }); } console.log('services seeded successfully'); } main() .catch((e) =&gt; { console.error(e); process.exit(1); }) .finally(async () =&gt; { await prisma.$disconnect(); });</file><file name="prisma/seeds/seedServices.ts">import { prismaclient } '@prisma/client'; const prisma = new prismaclient(); async function main() { const services = [ { title: " ", description: " . .", extrainfo: " , . , . , . , , ." }, { title: " ", description: " , , , . : , .", extrainfo: " , ." }, { title: " ", description: "subheading sets context, shares info author, generally gets people psyched keep reading", extrainfo: null }, { title: " ", description: " -. , .", extrainfo: " : , , (, , ), , . , . ." }, { title: " ", description: "subheading sets context, shares info author, generally gets people psyched keep reading", extrainfo: null }, { title: " ", description: "subheading sets context, shares info author, generally gets people psyched keep reading", extrainfo: null } ]; (const service services) { await prisma.service.create({ data: service }); } console.log('services seeded successfully'); } main() .catch((e) =&gt; { console.error(e); process.exit(1); }) .finally(async () =&gt; { await prisma.$disconnect(); });</file><file name="prisma/seeds/seedTags.js">const { prismaclient } = require('@prisma/client'); const prisma = new prismaclient(); async function main() { const tags = [ { name: '', color: '#ff5733' }, { name: '', color: '#33ff57' }, { name: '', color: '#5733ff' }, { name: '', color: '#ff3333' }, { name: '', color: '#33ffff' } ]; (const tag tags) { const { name, color } = tag; // create url-friendly slug name const slug = name .tolowercase() .normalize('nfd') .replace(/[\u0300-\u036f]/g, '') .replace(/[^a-z0-9]+/g, '-') .replace(/-+/g, '-') .trim(); await prisma.tag.upsert({ { slug }, update: { name, color }, create: { name, slug, color } }); } console.log('tags seeded successfully'); } main() .catch(e =&gt; { console.error(e); process.exit(1); }) .finally(async () =&gt; { await prisma.$disconnect(); });</file><file name="prisma/seeds/seedTags.new.js" /><file name="prisma/seeds/seedUsers.js">const { prismaclient } = require('@prisma/client'); const bcrypt = require('bcryptjs'); const prisma = new prismaclient(); async function main() { // const hashedpassword = await bcrypt.hash('admin123', 12); const admin = await prisma.user.upsert({ { email: 'admin@lawyer.com' }, update: { name: 'administrator', password: hashedpassword, role: 'admin', }, create: { name: 'administrator', email: 'admin@lawyer.com', password: hashedpassword, role: 'admin', }, }); console.log('admin user created updated:', admin.email); // const userpassword = await bcrypt.hash('user123', 12); const user = await prisma.user.upsert({ { email: 'user@lawyer.com' }, update: { name: 'test user', password: userpassword, role: 'user', }, create: { name: 'test user', email: 'user@lawyer.com', password: userpassword, role: 'user', }, }); console.log('test user created updated:', user.email); console.log('users seeded successfully'); } main() .catch((e) =&gt; { console.error(e); process.exit(1); }) .finally(async () =&gt; { await prisma.$disconnect(); });</file><file name="prisma/seeds/seedUsers.ts">import { prismaclient } '@prisma/client'; const prisma = new prismaclient(); async function main() { const users = [ { name: "admin user", email: "admin@example.com", role: "admin" }, { name: "john moderator", email: "john.moderator@example.com", role: "moderator" }, { name: "jane user", email: "jane.user@example.com", role: "user" }, { name: "mike client", email: "mike.client@example.com", role: "user" }, { name: "sarah manager", email: "sarah.manager@example.com", role: "moderator" } ]; (const user users) { await prisma.user.create({ data: user }); } console.log('users seeded successfully'); } main() .catch((e) =&gt; { console.error(e); process.exit(1); }) .finally(async () =&gt; { await prisma.$disconnect(); });</file><file name="scripts/migrate-file-urls.js" /><file name="scripts/prisma-runner.js">#!/usr/bin/env node /** * prisma * : direct_url supabase */ const { execsync } = require('child_process'); const fs = require('fs'); const path = require('path'); // .env function loadenvfile(filepath) { (!fs.existssync(filepath)) { console.error(` env file found: ${filepath}`); process.exit(1); } const envcontent = fs.readfilesync(filepath, 'utf-8'); const envvars = {}; envcontent.split('\n').foreach(line =&gt; { const trimmed = line.trim(); (trimmed &amp;&amp; !trimmed.startswith('#')) { const [key, ...valueparts] = trimmed.split('='); (key &amp;&amp; valueparts.length &gt; 0) { let value = valueparts.join('='); // ((value.startswith('"') &amp;&amp; value.endswith('"')) || (value.startswith("'") &amp;&amp; value.endswith("'"))) { value = value.slice(1, -1); } envvars[key] = value; } } }); return envvars; } // function runprismacommand() { const [command, ...args] = process.argv.slice(2); (!command) { console.log('usage: node prisma-runner.js &lt;prisma-command&gt; [args...]'); console.log('example: node prisma-runner.js migrate deploy --prod'); process.exit(1); } // const isprod = args.includes('--prod'); const envfile = isprod ? '.env.production' : '.env.local'; const envpath = path.join(process.cwd(), envfile); console.log(` loading environment ${envfile}`); // const envvars = loadenvfile(envpath); // process.env object.assign(process.env, envvars); // supabase direct_url (isprod &amp;&amp; (command === 'migrate' || command === 'db')) { (envvars.direct_url) { console.log(' using direct_url supabase migration (bypassing pgbouncer)'); process.env.database_url = envvars.direct_url; } } // const filteredargs = args.filter(arg =&gt; arg !== '--prod'); const prismacommand = `npx prisma ${command} ${filteredargs.join(' ')}`.trim(); console.log(` executing: ${prismacommand}`); console.log(` database: ${process.env.database_url?.substring(0, 50)}...`); try { execsync(prismacommand, { stdio: 'inherit', cwd: process.cwd(), env: process.env }); console.log(' command completed successfully!'); } catch (error) { console.error(' command failed:', error.message); process.exit(1); } } runprismacommand();</file><file name="scripts/database/db-util.mjs" /><file name="scripts/database/deploy.mjs" /><file name="scripts/database/migrate.js" /><file name="scripts/database/reset.mjs" /><file name="scripts/database/seed.mjs" /><file name="scripts/database/studio.mjs" /><file name="src/middleware.ts">import { nextrequest, nextresponse } 'next/server' export async function middleware(request: nextrequest) { const { pathname } = request.nexturl // api (pathname.startswith('/api/files') || pathname.startswith('/api/upload') || pathname.startswith('/api/tags')) { const sessioncookie = request.cookies.get('admin-session') (!sessioncookie?.value) { return nextresponse.json({ error: 'unauthorized' }, { status: 401 }) } try { const user = json.parse(sessioncookie.value) // ((pathname.startswith('/api/tags') &amp;&amp; (request.method === 'post' || request.method === 'put' || request.method === 'delete')) || pathname.startswith('/api/upload')) { (user.role !== 'admin' &amp;&amp; user.role !== 'editor') { return nextresponse.json({ error: 'access denied' }, { status: 403 }) } } } catch { return nextresponse.json({ error: 'invalid session' }, { status: 401 }) } } // (pathname.startswith('/admin') &amp;&amp; !pathname.startswith('/admin/login')) { const sessioncookie = request.cookies.get('admin-session') (!sessioncookie?.value) { return nextresponse.redirect(new url('/admin/login', request.url)) } try { const user = json.parse(sessioncookie.value) // admin (user.role !== 'admin') { return nextresponse.redirect(new url('/admin/login', request.url)) } } catch { return nextresponse.redirect(new url('/admin/login', request.url)) } } // editor (pathname.startswith('/editor')) { const sessioncookie = request.cookies.get('admin-session') (!sessioncookie?.value) { return nextresponse.redirect(new url('/admin/login', request.url)) } try { const user = json.parse(sessioncookie.value) // editor editor (user.role !== 'editor') { return nextresponse.redirect(new url('/admin/login', request.url)) } } catch { return nextresponse.redirect(new url('/admin/login', request.url)) } } // (pathname.startswith('/uploads/')) { // , uploads // return nextresponse.next() } return nextresponse.next() } export const config = { matcher: [ '/api/files/:path*', '/api/upload/:path*', '/api/tags/:path*', '/admin/:path*', '/editor/:path*', '/uploads/:path*' ] }</file><file name="src/app/globals.css">@import "tailwindcss"; /* richtexteditor */ .rich-text-content table { border-collapse: collapse; width: 100%; margin: 10px 0; border: 1px solid #dee2e6; } .rich-text-content th, .rich-text-content td { border: 1px solid #dee2e6; padding: 8px; } .rich-text-content th { background-color: #f8f9fa; font-weight: bold; } .rich-text-content .table-bordered { border: 1px solid #dee2e6; } .rich-text-content .table-bordered th, .rich-text-content .table-bordered td { border: 1px solid #dee2e6; padding: 8px; } .rich-text-content .table-striped tbody tr:nth-of-type(odd) { background-color: rgba(0, 0, 0, 0.05); } .rich-text-content .table-header { background-color: #f8f9fa; font-weight: bold; } .rich-text-content .table-header-row { background-color: #e9ecef; } .rich-text-content .table-alt-row { background-color: #f8f9fa; } .rich-text-content .table-highlight { background-color: #fff3cd; } /* - */ .rich-text-content img { max-width: 100%; height: auto; } .prose-custom img { max-width: 100%; height: auto; } /* ( prose) */ .prose-custom { font-size: 1.125rem; line-height: 1.75; color: #374151; } .prose-custom p { margin-top: 1.25em; margin-bottom: 1.25em; } .prose-custom h1, .prose-custom h2, .prose-custom h3, .prose-custom h4, .prose-custom h5, .prose-custom h6 { font-weight: 600; line-height: 1.25; margin-top: 2em; margin-bottom: 1em; } .prose-custom h1 { font-size: 2.25em; } .prose-custom h2 { font-size: 1.875em; } .prose-custom h3 { font-size: 1.5em; } .prose-custom h4 { font-size: 1.25em; } .prose-custom ul, .prose-custom ol { margin-top: 1.25em; margin-bottom: 1.25em; padding-left: 1.625em; } .prose-custom li { margin-top: 0.5em; margin-bottom: 0.5em; } .prose-custom blockquote { border-left: 4px solid #e5e7eb; padding-left: 1em; font-style: italic; margin: 1.5em 0; } /* */ table { border-collapse: collapse; } table th, table td { border: 1px solid #dee2e6; padding: 8px; } table th { background-color: #f8f9fa; font-weight: bold; }</file><file name="src/app/globals.sass">@use "tailwindcss";</file><file name="src/app/layout.tsx">import type { metadata } "next"; import { toaster } "sonner"; import "./globals.sass"; export const metadata: metadata = { title: "create next app", description: "generated create next app", }; export default function rootlayout({ children }: { children: react.reactnode }) { return ( &lt;html lang="en"&gt; &lt;body&gt; {children} &lt;toaster /&gt; &lt;/body&gt; &lt;/html&gt; ); }</file><file name="src/app/page.tsx">import react "react"; import sectioninfo "../components/section/sectioninfo"; import sectionservices "../components/section/sectionservices"; import header "../components/ui/header"; import sectionactuality "../components/section/sectionactuality"; import footer "../components/ui/footer"; import homeclient "../components/ui/homeclient"; export default function home() { return ( &lt;&gt; &lt;header /&gt; &lt;sectioninfo /&gt; &lt;sectionservices /&gt; &lt;homeclient /&gt; &lt;sectionactuality /&gt; &lt;footer /&gt; &lt;/&gt; ); }</file><file name="src/app/(services)/[slug]/page.tsx">import { notfound } 'next/navigation' import header '@/components/ui/header' import servicedescriptionclient '@/components/ui/servicedescriptionclient' import servicedetails '@/components/ui/servicedetails' import buttonfeedbackclient '@/components/ui/buttonfeedbackclient' import footer '@/components/ui/footer' import { getservicebyslug, getallserviceslugs } '@/lib/services' interface servicepageprops { params: promise&lt;{ slug: string }&gt; } export async function generatestaticparams() { const slugs = await getallserviceslugs() return slugs.map((slug) =&gt; ({ slug, })) } export default async function servicepage({ params }: servicepageprops) { const { slug } = await params const service = await getservicebyslug(slug) (!service) { notfound() } // parse services features array // parse services features array const features = service.details .flatmap(detail =&gt; detail.services.split('\n')) .filter(line =&gt; line.trim()) .map(line =&gt; line.replace(/^\d+\.\s*/, '').trim()) return ( &lt;div classname="min-h-screen flex flex-col"&gt; &lt;header /&gt; &lt;main classname="flex-1"&gt; &lt;servicedescriptionclient title={service.title} shortdescription={service.description} features={features.slice(0, 5)} // show first 5 features /&gt; &lt;servicedetails fulldescription={service.extrainfo || service.description} features={features} benefits={[ " ", " ", " ", " " ]} price=" " duration=" " /&gt; &lt;buttonfeedbackclient /&gt; &lt;/main&gt; &lt;footer /&gt; &lt;/div&gt; ) }</file><file name="src/app/actions/filemanager/articleFiles.ts">'use server' import { prisma } '@/lib/prisma' import { prisma } '@prisma/client' import { buildfilepath } './getfilepath' /** * */ export async function getarticlefileswithpaths(articleid: number) { try { const article = await prisma.article.findunique({ { id: articleid } }) (!article || !article.documents) { return { success: true, files: [] } } const documentids = json.parse(article.documents string) number[] const fileswithpaths = [] (const fileid documentids) { const file = await prisma.file.findunique({ { id: fileid } }) (file) { const actualpath = await buildfilepath(fileid) fileswithpaths.push({ id: file.id, originalname: file.originalname, filename: file.filename, mimetype: file.mimetype, size: file.size, url: actualpath ? `/${actualpath}` : null, isvalid: !!actualpath }) } } return { success: true, files: fileswithpaths } } catch (error) { console.error('error getting article files:', error) return { success: false, error: 'failed get article files' } } } /** * */ export async function fixbrokenlinksinarticles() { try { const articles = await prisma.article.findmany({ { documents: { prisma.jsonnull } } }) let fixedcount = 0 const errors = [] (const article articles) { try { const documentids = json.parse(article.documents string) number[] const validids = [] (const fileid documentids) { const file = await prisma.file.findunique({ { id: fileid } }) (file) { const actualpath = await buildfilepath(fileid) (actualpath) { validids.push(fileid) } } } // (validids.length !== documentids.length) { await prisma.article.update({ { id: article.id }, data: { documents: json.stringify(validids) } }) fixedcount++ } } catch (error) { errors.push(`article ${article.id}: ${error}`) } } return { success: true, fixedcount, errors } } catch (error) { console.error('error fixing broken links:', error) return { success: false, error: 'failed fix broken links' } } }</file><file name="src/app/actions/filemanager/checkFileUsage.ts">'use server' import { prisma } '@/lib/prisma' /** * , * @param fileid id * @returns */ export async function checkfileusage(fileid: number) { try { // const file = await prisma.file.findunique({ { id: fileid } }) (!file) { return { isused: false, usedin: [] } } // const articles = await prisma.article.findmany({ select: { id: true, title: true, content: true, documents: true } }) const usedin: array&lt;{ id: number; title: string; type: 'content' | 'document' }&gt; = [] (const article articles) { // (article.content) { // /api/files/[id] const fileidpattern = new regexp(`/api/files/${fileid}(?![0-9])`, 'g') // virtualid let virtualidpattern: regexp | null = null (file.virtualid) { virtualidpattern = new regexp(`/api/files/${file.virtualid}(?![a-za-z0-9_-])`, 'g') } // const filenamepattern = new regexp(file.filename.replace(/[.*+?^${}()|[\]\\]/g, '\\$&amp;'), 'g') (fileidpattern.test(article.content) || (virtualidpattern &amp;&amp; virtualidpattern.test(article.content)) || filenamepattern.test(article.content)) { usedin.push({ id: article.id, title: article.title, type: 'content' }) } } // (article.documents) { try { const documentids = json.parse(article.documents string) number[] (documentids.includes(fileid)) { usedin.push({ id: article.id, title: article.title, type: 'document' }) } } catch { // json } } } return { isused: usedin.length &gt; 0, usedin } } catch (error) { console.error('error checking file usage:', error) return { isused: false, usedin: [] } } } /** * * @param fileids id * @returns */ export async function checkmultiplefilesusage(fileids: number[]) { try { const results: record&lt;number, { isused: boolean; usedin: array&lt;{ id: number; title: string; type: 'content' | 'document' }&gt; }&gt; = {} (const fileid fileids) { results[fileid] = await checkfileusage(fileid) } return results } catch (error) { console.error('error checking multiple files usage:', error) return {} } }</file><file name="src/app/actions/filemanager/createFolder.ts">"use server" import { prismaclient } '@prisma/client' import { cookies } 'next/headers' import { mkdir } 'fs/promises' import { join } 'path' import { getstorageinfo } '@/lib/utils/universal-file-utils' import { validateandprocessfoldername } '@/lib/utils/folder-validation' const prisma = new prismaclient() export interface createfolderresult { success: boolean folder?: { id: number originalname: string filename: string mimetype: string size: number createdat: string url: string isfolder: boolean path: string } error?: string } /** * * @param name * @param parentid id (null ) */ export async function createfolder(name: string, parentid: number | null = null): promise&lt;createfolderresult&gt; { console.log('createfolder called { name, parentid, storageprovider: process.env.storage_provider }) try { const cookiestore = await cookies() const sessioncookie = cookiestore.get('admin-session') (!sessioncookie?.value) { return { success: false, error: 'unauthorized' } } const user = json.parse(sessioncookie.value) (!user?.id) { return { success: false, error: 'user found' } } (!name.trim()) { return { success: false, error: 'folder name required' } } // const storagetype = getstorageinfo() console.log('creating folder storage provider:', storagetype.provider) // const validation = validateandprocessfoldername(name.trim(), storagetype.provider 'local' | 'supabase') (!validation.success) { return { success: false, error: validation.error + (validation.suggestions ? ` suggestions: ${validation.suggestions.join(', ')}` : '') } } const { originalname, safename, wastransliterated } = validation.data // (wastransliterated) { console.log(`folder name transliterated: "${originalname}" -&gt; "${safename}"`) } // let fullpath: string let parentfolder = null (parentid) { // , parentfolder = await prisma.folder.findunique({ { id: parentid, ownerid: user.id // }, select: { path: true } }) (!parentfolder) { return { success: false, error: 'parent folder found' } } fullpath = `${parentfolder.path}/${name}` } else { // fullpath = `user_${user.id}/${name}` } // const folder = await prisma.folder.create({ data: { name: safename, // path: fullpath, ownerid: user.id, parentid: parentid || null } }) // // supabase storage const storagedata = getstorageinfo(); console.log('storage provider info:', storagedata); (storagedata.islocal) { console.log('creating physical folder local storage provider') // const uploadsdir = join(process.cwd(), 'public', 'uploads') const physicalpath = join(uploadsdir, fullpath) await mkdir(physicalpath, { recursive: true }) } else { console.log('skipping physical folder creation (using cloud storage - folders created automatically)') } // fileitem const folderresult = { id: folder.id, originalname: folder.name, filename: folder.name, mimetype: 'folder', size: 0, createdat: folder.createdat.toisostring(), url: `/uploads/${folder.path}`, isfolder: true, path: folder.path } return { success: true, folder: folderresult } } catch (error) { console.error('create folder error:', error) return { success: false, error: 'failed create folder' } } }</file><file name="src/app/actions/filemanager/deleteFile.ts">"use server" import { prismaclient } '@prisma/client' import { cookies } 'next/headers' import { checkfileusage } './checkfileusage' import { deletefile deletefilefromstorage } '@/lib/utils/universal-file-utils' const prisma = new prismaclient() export interface deletefileresult { success: boolean error?: string isused?: boolean usedin?: array&lt;{ id: number; title: string; type: 'content' | 'document' }&gt; } /** * * @param fileid id * @param force */ export async function deletefile(fileid: number, force: boolean = false): promise&lt;deletefileresult&gt; { try { const cookiestore = await cookies() const sessioncookie = cookiestore.get('admin-session') (!sessioncookie?.value) { return { success: false, error: 'unauthorized' } } const user = json.parse(sessioncookie.value) (!user?.id) { return { success: false, error: 'user found' } } // const file = await prisma.file.findunique({ { id: fileid } }) (!file) { return { success: false, error: 'file found' } } // (file.uploadedby !== user.id) { return { success: false, error: 'access denied' } } // ( ) (!force) { const usage = await checkfileusage(fileid) (usage.isused) { return { success: false, error: 'file used articles', isused: true, usedin: usage.usedin } } } // try { // let filepath = file.path; // url, (filepath.startswith('/uploads/')) { filepath = filepath.substring(9); // '/uploads/' } else (filepath.startswith('uploads/')) { filepath = filepath.substring(8); // 'uploads/' } else (filepath.startswith('https://')) { // s3/supabase url const urlparts = filepath.split('/'); const userindex = urlparts.findindex(part =&gt; part.startswith('user_')); (userindex !== -1) { filepath = urlparts.slice(userindex).join('/'); } } console.log('deleting file storage:', filepath); const deleteresult = await deletefilefromstorage(filepath); (!deleteresult.success) { console.warn('failed delete file storage:', deleteresult.error); // } } catch (storageerror) { console.error('failed delete file storage:', storageerror); // } // await prisma.file.delete({ { id: fileid } }) return { success: true } } catch (error) { console.error('file deletion error:', error) return { success: false, error: 'failed delete file' } } }</file><file name="src/app/actions/filemanager/deleteFolder.ts">"use server" import { prismaclient } '@prisma/client' import { cookies } 'next/headers' import { rmdir } 'fs/promises' import { join } 'path' import { deletefile } '@/lib/utils/universal-file-utils' import { getstorageinfo } '@/lib/utils/universal-file-utils' const prisma = new prismaclient() export interface deletefolderresult { success: boolean error?: string } /** * * @param folderid id * @param force true, */ export async function deletefolder(folderid: number, force: boolean = false): promise&lt;deletefolderresult&gt; { try { const cookiestore = await cookies() const sessioncookie = cookiestore.get('admin-session') (!sessioncookie?.value) { return { success: false, error: 'unauthorized' } } const user = json.parse(sessioncookie.value) (!user?.id) { return { success: false, error: 'user found' } } // const folder = await prisma.folder.findunique({ { id: folderid }, include: { files: true, children: { include: { files: true, children: true } } } }) (!folder) { return { success: false, error: 'folder found' } } // (folder.ownerid !== user.id) { return { success: false, error: 'access denied' } } // force , , (!force &amp;&amp; (folder.files.length &gt; 0 || folder.children.length &gt; 0)) { return { success: false, error: 'folder empty. use force=true delete contents.' } } // const deleterecursively = async (currentfolderid: number) =&gt; { // const files = await prisma.file.findmany({ { folderid: currentfolderid } }) // (const file files) { try { // await deletefile(file.path); } catch (storageerror) { console.error('failed delete file storage:', storageerror) // } // await prisma.file.delete({ { id: file.id } }) } // const children = await prisma.folder.findmany({ { parentid: currentfolderid } }) // (const child children) { await deleterecursively(child.id) } // await prisma.folder.delete({ { id: currentfolderid } }) } // await deleterecursively(folderid) // // supabase storage const storageinfo = getstorageinfo(); (storageinfo.islocal) { try { const absolutepath = join(process.cwd(), 'public', 'uploads', folder.path) await rmdir(absolutepath, { recursive: true }) console.log('physical folder deleted local storage') } catch (fserror) { console.error('failed delete folder local filesystem:', fserror) // , } } else { console.log('skipping physical folder deletion (cloud storage)') } return { success: true } } catch (error) { console.error('folder deletion error:', error) return { success: false, error: 'failed delete folder' } } }</file><file name="src/app/actions/filemanager/editor.ts">"use server" import { createfilemanagerprovider } '@/lib/filemanager/factory' import { revalidatepath } 'next/cache' /** * server action richtexteditor * */ export async function uploadfileforeditor(formdata: formdata) { try { const provider = await createfilemanagerprovider() (!provider) { return { success: false, error: 'unauthorized', file: null } } const file = formdata.get('file') file (!file) { return { success: false, error: file provided', file: null } } // provider const validation = provider.validatefileupload(file) (!validation.success) { return { success: false, error: validation.error, file: null } } const result = await provider.uploadfiles([file]) (result.success &amp;&amp; result.files.length &gt; 0) { const uploadedfile = result.files[0] // url const urlresult = await provider.getfileurl(uploadedfile.id) // revalidatepath('/admin/articles') revalidatepath('/editor/articles') return { success: true, file: { id: uploadedfile.id, url: urlresult.data || `/api/files/${uploadedfile.id}`, originalname: uploadedfile.originalname, mimetype: uploadedfile.mimetype, size: uploadedfile.size }, error: null } } else { return { success: false, error: result.error || 'upload failed', file: null } } } catch (error) { console.error('uploadfileforeditor error:', error) return { success: false, error: 'internal server error', file: null } } } /** * server action * , */ export async function getfilesforeditor(filters: { folderid?: number mimetypes?: string[] searchquery?: string limit?: number } = {}) { try { const provider = await createfilemanagerprovider() (!provider) { return { success: false, error: 'unauthorized', files: [] } } const result = await provider.listfiles({ ...filters, sortby: 'createdat', sortorder: 'desc' }) (result.success) { // const editorfiles = await promise.all( (result.data || []).map(async (file) =&gt; { const urlresult = await provider.getfileurl(file.id) return { id: file.id, url: urlresult.data || `/api/files/${file.id}`, originalname: file.originalname, mimetype: file.mimetype, size: file.size, createdat: file.createdat } }) ) return { success: true, files: editorfiles, error: null, permissions: provider.permissions } } else { return { success: false, error: result.error || 'failed load files', files: [] } } } catch (error) { console.error('getfilesforeditor error:', error) return { success: false, error: 'internal server error', files: [] } } } /** * server action * */ export async function validatefileaccess(fileid: number) { try { const provider = await createfilemanagerprovider() (!provider) { return { success: false, hasaccess: false, error: 'unauthorized' } } const hasaccess = await provider.canaccessfile(fileid) (hasaccess) { const fileresult = await provider.getfiledetails(fileid) const urlresult = await provider.getfileurl(fileid) (fileresult.success &amp;&amp; urlresult.success) { return { success: true, hasaccess: true, file: { id: fileresult.data!.id, url: urlresult.data!, originalname: fileresult.data!.originalname, mimetype: fileresult.data!.mimetype }, error: null } } } return { success: true, hasaccess: false, file: null, error: null } } catch (error) { console.error('validatefileaccess error:', error) return { success: false, hasaccess: false, file: null, error: 'internal server error' } } } /** * server action * */ export async function getuserfilepermissions() { try { const provider = await createfilemanagerprovider() (!provider) { return { success: false, permissions: null, error: 'unauthorized' } } return { success: true, permissions: { canupload: provider.permissions.canuploadfiles, candelete: provider.permissions.candeleteownfiles, canviewall: provider.permissions.canviewallfiles, canmanagefolders: provider.permissions.canmanagefolders, maxfilesize: provider.permissions.maxfilesize, allowedtypes: provider.permissions.allowedmimetypes }, error: null } } catch (error) { console.error('getuserfilepermissions error:', error) return { success: false, permissions: null, error: 'internal server error' } } }</file><file name="src/app/actions/filemanager/filePathManager.ts">'use server' import { prisma } '@/lib/prisma' /** * middleware * */ export class filepathmanager { /** * */ static async updatefilepathsafterfolderrename(folderid: number) { try { // const affectedfiles = await this.getallfilesinfoldertree(folderid) // (const file affectedfiles) { const newpath = await this.calculatefilepath(file.id) (newpath &amp;&amp; newpath !== file.path) { await prisma.file.update({ { id: file.id }, data: { path: newpath } }) } } console.log(`updated paths ${affectedfiles.length} files`) } catch (error) { console.error('error updating file paths:', error) throw error } } /** * ( ) */ private static async getallfilesinfoldertree(folderid: number): promise&lt;array&lt;{ id: number path: string filename: string folderid: number | null }&gt;&gt; { const files = [] // const directfiles = await prisma.file.findmany({ { folderid } }) files.push(...directfiles) // const subfolders = await prisma.folder.findmany({ { parentid: folderid } }) // (const subfolder subfolders) { const subfiles = await this.getallfilesinfoldertree(subfolder.id) files.push(...subfiles) } return files } /** * */ private static async calculatefilepath(fileid: number): promise&lt;string | null&gt; { const file = await prisma.file.findunique({ { id: fileid }, include: { folder: true } }) (!file) return null (!file.folder) { return `uploads/${file.filename}` } const folderpath = await this.calculatefolderpath(file.folder.id) return `uploads/${folderpath}/${file.filename}` } /** * */ private static async calculatefolderpath(folderid: number): promise&lt;string&gt; { const folder = await prisma.folder.findunique({ { id: folderid }, include: { parent: true } }) (!folder) return '' (!folder.parent) { return folder.name } const parentpath = await this.calculatefolderpath(folder.parent.id) return `${parentpath}/${folder.name}` } /** * * ( ) */ static async syncallfilepaths() { try { const allfiles = await prisma.file.findmany() let updatedcount = 0 (const file allfiles) { const correctpath = await this.calculatefilepath(file.id) (correctpath &amp;&amp; correctpath !== file.path) { await prisma.file.update({ { id: file.id }, data: { path: correctpath } }) updatedcount++ } } console.log(`synchronized ${updatedcount} file paths`) return { success: true, updatedcount } } catch (error) { console.error('error syncing file paths:', error) return { success: false, error: error instanceof error ? error.message : 'unknown error' } } } } /** * hook actions */ export async function afterfolderupdate(folderid: number) { await filepathmanager.updatefilepathsafterfolderrename(folderid) }</file><file name="src/app/actions/filemanager/files.ts">"use server" import { createfilemanagerprovider } '@/lib/filemanager/factory' import { filelistfilters } '@/lib/filemanager/types' import { revalidatepath } 'next/cache' /** * server action */ export async function getfileslist(filters: filelistfilters = {}) { try { const provider = await createfilemanagerprovider() (!provider) { return { success: false, error: 'unauthorized', files: [], permissions: null } } const result = await provider.listfiles(filters) return { success: result.success, files: result.data || [], error: result.error, permissions: provider.permissions } } catch (error) { console.error('getfileslist error:', error) return { success: false, error: 'internal server error', files: [], permissions: null } } } /** * server action */ export async function uploadfiles(formdata: formdata) { try { const provider = await createfilemanagerprovider() (!provider) { return { success: false, error: 'unauthorized', files: [] } } const files = formdata.getall('files') file[] const folderid = formdata.get('folderid') ? parseint(formdata.get('folderid') string) : undefined (!files.length) { return { success: false, error: files provided', files: [] } } const result = await provider.uploadfiles(files, folderid) // , (result.success) { revalidatepath('/admin/files') revalidatepath('/editor/files') revalidatepath('/admin/articles') revalidatepath('/editor/articles') } return { success: result.success, files: result.files, error: result.error, permissions: provider.permissions } } catch (error) { console.error('uploadfiles error:', error) return { success: false, error: 'internal server error', files: [] } } } /** * server action */ export async function deletefile(fileid: number) { try { const provider = await createfilemanagerprovider() (!provider) { return { success: false, error: 'unauthorized', deletedids: [] } } const result = await provider.deletefile(fileid) // (result.success) { revalidatepath('/admin/files') revalidatepath('/editor/files') revalidatepath('/admin/articles') revalidatepath('/editor/articles') } return { success: result.success, deletedids: result.deletedids, error: result.error, permissions: provider.permissions } } catch (error) { console.error('deletefile error:', error) return { success: false, error: 'internal server error', deletedids: [] } } } /** * server action */ export async function deletefiles(fileids: number[]) { try { const provider = await createfilemanagerprovider() (!provider) { return { success: false, error: 'unauthorized', deletedids: [] } } const result = await provider.deletefiles(file